{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "y1xXL2jdBdff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "_IZay8W4Bgp9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary resources\n"
      ],
      "metadata": {
        "id": "C8dvIUnhBhjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "ZUzaKoa_BjEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727cb452-51bd-4cd9-dadb-5a9ec901d62e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "EWP_F1sYBkEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "OkTzhGvsBldA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Tokenize the sentence\n",
        "# Tokenization is the process of breaking down the text into individual words or tokens."
      ],
      "metadata": {
        "id": "dJA1CBrMBl5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "id": "lz4mtx9oBq2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7026f233-2efa-4b76-f5c2-b49169776962"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Perform Part of Speech (PoS) tagging\n",
        "# PoS tagging assigns a part of speech to each word (e.g., noun, verb, adjective)."
      ],
      "metadata": {
        "id": "zVaGjcGwBsuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "id": "i7SZQIfEBuQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29133fe2-08fa-4173-eedc-ba5dfd6e2b19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "The output of pos_tag is a list of tuples, where each tuple contains a word and its corresponding PoS tag.\n",
        "Common PoS tags include:\n",
        " - NN: Noun\n",
        " - VB: Verb\n",
        " - JJ: Adjective\n",
        " - RB: Adverb\n",
        " - IN: Preposition"
      ],
      "metadata": {
        "id": "jgToAf0GByEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract specific parts of speech\n",
        " Let's extract all nouns (NN) from the tagged words."
      ],
      "metadata": {
        "id": "FG1YwXy7B8de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "id": "zzxtRMP1B94s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68104a9-32bf-42fb-bb02-6351ea65c6b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Count the occurrences of each PoS tag\n",
        "We can use a Counter to count how many times each PoS tag appears in the sentence."
      ],
      "metadata": {
        "id": "zwoKuYF2CAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"\\nPoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "NTvpb5MxCCz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf323145-9c44-44e4-a57b-8916f37c6c11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Extract all verbs from the sentence\n",
        "Verbs can have different tags like VB, VBD (past tense), VBG (gerund), etc."
      ],
      "metadata": {
        "id": "W__OyoOXCEsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ke_HUhQLAc_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7383ec9b-c1c5-4674-8ec0-e0e5f9a92099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verbs: ['jumps']\n"
          ]
        }
      ],
      "source": [
        "verbs = [word for word, pos in tagged_words if pos.startswith('VB')]\n",
        "print(\"\\nVerbs:\", verbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "nJ_k6hE8CZr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "J34LLTqACaFS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "0UGjpQb9CbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "-PxjEVcnCdWA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "Z5QsOidjCeRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0SUTfcD474P",
        "outputId": "a9f75943-5ee4-4c7a-e6bf-7f18d11f5b88"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsub49184_cL",
        "outputId": "2cceb095-4b30-4a21-885b-fcfa364fa275"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Extract only the nouns (NN) from the tagged words\n"
      ],
      "metadata": {
        "id": "xeS1f0hnCiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDXoMsCL5Dqs",
        "outputId": "31c95bb1-e2e0-4e89-b0ca-f5b533a331b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "m7-jj2BLClGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QrutpKbmCmZk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence"
      ],
      "metadata": {
        "id": "Y814v2cECm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "bAotCj-TCqCb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "KMGD0NHSCsSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx3SS1FC5Imo",
        "outputId": "43171e65-0224-4452-f145-aa478f074887"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8osA6fOi5Kyt",
        "outputId": "9b27754e-7e75-4d13-a419-9cb23e9ee173"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Count the occurrences of each PoS tag"
      ],
      "metadata": {
        "id": "fnVaIBJcCyhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"\\nPoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "OIaf_UU35StZ",
        "outputId": "9a090ff0-5fdc-4a48-ac93-bcbb6a6d2168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pniIX65L5UNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}